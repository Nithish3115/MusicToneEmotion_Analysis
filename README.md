# ğŸµ Music Emotion Recognition System

A full-stack application that analyzes audio files and predicts emotional characteristics using deep learning. The system provides real-time emotion analysis across **8 different dimensions**.

![Music Emotion Recognition](https://img.shields.io/badge/Status-Active-brightgreen)
![Python](https://img.shields.io/badge/Python-3.10+-blue)
![React](https://img.shields.io/badge/React-18+-61DAFB)
![FastAPI](https://img.shields.io/badge/FastAPI-Latest-009688)
![TypeScript](https://img.shields.io/badge/TypeScript-5+-3178C6)

---

## ğŸŒŸ Features

- ğŸ¯ **Real-time Emotion Analysis** â€” Upload audio files and get instant emotion predictions  
- ğŸ“Š **8 Emotion Dimensions** â€” Analyzes valence, energy, tension, anger, fear, happiness, sadness, and tenderness  
- ğŸ¨ **Modern UI** â€” Beautiful React interface with dark/light theme support  
- âš¡ **Fast Processing** â€” Optimized neural network for quick predictions  
- ğŸ“± **Responsive Design** â€” Works seamlessly on desktop and mobile devices  
- ğŸ”„ **Real-time Updates** â€” Live processing status and results display  

---


## ğŸš€ Quick Start

### ğŸ§© Prerequisites

- **Python 3.10+**  
- **Node.js 18+**  
- **npm** or **yarn**

---

### 1. Clone Repository

```bash
git clone https://github.com/Nithish3115/MusicToneEmotion_Analysis.git
cd MusicToneEmotion_Analysis
```
### 2. Backend Setup

```bash

cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start the backend server
python -m app.main
```
Backend will be running at: http://localhost:8000

### 3. Frontend Setup
```bash
cd Frontend

# Install dependencies
npm install

# Start development server
npm run dev
```
Frontend will be running at: http://localhost:5000

### 4. Open Application
Navigate to http://localhost:5000 in your browser and start analyzing audio files!


### ğŸ“ Project Structure
```bash
music-emotion-recognition/
â”‚
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/routes/        # API endpoints
â”‚   â”‚   â”œâ”€â”€ core/              # Core business logic
â”‚   â”‚   â”œâ”€â”€ models/            # ML models and preprocessing
â”‚   â”‚   â””â”€â”€ main.py            # FastAPI application
â”‚   â”œâ”€â”€ best.pth              # Trained model weights
â”‚   â”œâ”€â”€ test_data/            # Sample audio files
â”‚   â””â”€â”€ requirements.txt      # Python dependencies
â”‚
â”œâ”€â”€ Frontend/                   # React + Express Frontend
â”‚   â”œâ”€â”€ client/src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ pages/            # Application pages
â”‚   â”‚   â”œâ”€â”€ lib/              # API integration
â”‚   â”‚   â””â”€â”€ hooks/            # Custom React hooks
â”‚   â”œâ”€â”€ server/               # Express server
â”‚   â””â”€â”€ package.json          # Node.js dependencies
â”‚
â””â”€â”€ README.md                  # This file
```

## ğŸ¯ API Endpoints

**Backend (FastAPI) â€” Port 8000**


| Method | Endpoint     | Description                              |
|--------|---------------|------------------------------------------|
| GET    | `/`           | API information                          |
| GET    | `/health/`    | Health check and model status            |
| POST   | `/predict/`   | Upload audio file for emotion analysis   |
| GET    | `/docs`       | Interactive API documentation            |

Example API Usage

```
# Health check
curl http://localhost:8000/health/

# Predict emotions
curl -X POST "http://localhost:8000/predict/" \
     -F "file=@path/to/audio.mp3"
```

## Response Format

```
{
  "success": true,
  "filename": "song.mp3",
  "emotions": {
    "valence": 5.23,
    "energy": 6.12,
    "tension": 3.45,
    "anger": 2.11,
    "fear": 1.87,
    "happy": 6.54,
    "sad": 2.34,
    "tender": 4.76
  },
  "processing_time": 1.2,
  "message": "Emotion prediction completed successfully"


}
```


### ğŸ§  Model Information

## Audio2EmotionModel Architecture

**Base:** VGG-style Convolutional Neural Network  

| Attribute       | Description                                |
|-----------------|--------------------------------------------|
| **Input**       | Audio spectrograms (256 Ã— 1292)            |
| **Output**      | 8 emotion dimensions (scores 1.0 - 7.83)  |
| **Framework**   | PyTorch                                    |
| **Preprocessing** | Log spectrograms using librosa           |


## ğŸ­ Emotion Dimensions

| Emotion  | Description                  | Range       |
|----------|------------------------------|------------|
| Valence  | Positive vs. Negative emotion | 1.0 - 7.83 |
| Energy   | High vs. Low energy level     | 1.0 - 7.83 |
| Tension  | Stress vs. Relaxation         | 1.0 - 7.83 |
| Anger    | Anger intensity               | 1.0 - 7.83 |
| Fear     | Fear level                    | 1.0 - 7.83 |
| Happy    | Happiness level               | 1.0 - 7.83 |
| Sad      | Sadness level                 | 1.0 - 7.83 |
| Tender   | Tenderness level              | 1.0 - 7.83 |


## ğŸµ Supported Audio Formats

| Format | Extension  |
|--------|-----------|
| MP3    | .mp3      |
| WAV    | .wav      |
| FLAC   | .flac     |
| M4A    | .m4a      |
| OGG    | .ogg      |

**Maximum file size:** 50MB


### ğŸ› ï¸ Technology Stack

## ğŸ–¥ï¸ Backend

| Technology | Description                        |
|------------|------------------------------------|
| FastAPI    | Modern Python web framework        |
| PyTorch    | Deep learning framework            |
| Librosa    | Audio processing library           |
| Uvicorn    | ASGI server                        |
| Pydantic   | Data validation                    |

## ğŸŒ Frontend

| Technology       | Description                        |
|-----------------|------------------------------------|
| React 18         | UI library                         |
| TypeScript       | Type-safe JavaScript               |
| TanStack Query   | Server state management            |
| Tailwind CSS     | Utility-first CSS                  |
| Shadcn/ui        | Modern UI components               |
| Vite             | Build tool                         |
| Express.js       | Node.js server                     |


### ğŸ¨ UI Components

| Feature                   | Description                                      |
|---------------------------|--------------------------------------------------|
| ğŸŒ™ Dark/Light Theme        | Toggle between themes with persistence          |
| ğŸ“¤ Drag & Drop Upload      | Intuitive file upload interface                 |
| ğŸ“Š Emotion Cards           | Visual representation of emotion scores        |
| â±ï¸ Real-time Processing     | Live updates during analysis                    |
| ğŸ“± Responsive Design       | Mobile-friendly interface                        |
| ğŸ”” Toast Notifications     | User feedback for actions                        |


### ğŸ§ª Testing

Backend Testing
```
cd backend
python -m pytest tests/
```
Frontend Testing
```
cd Frontend
npm test
```

Manual Testing
```
# Test with sample audio file
curl -X POST "http://localhost:8000/predict/" \
     -F "file=@backend/test_data/Valence.mp3"
```


### ğŸ”§ Configuration

Environment Variables
Create .env files in both backend and frontend directories:

## Backend .env:
```
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=False
MODEL_PATH=best.pth
LOG_LEVEL=INFO
```

## Frontend .env:
```
VITE_API_BASE_URL=http://localhost:8000
```

### ğŸ“ˆ Performance

| Metric                    | Details                                    |
|----------------------------|--------------------------------------------|
| Model Inference            | ~1-3 seconds per audio file               |
| Memory Usage               | ~500MB (with loaded model)                |
| Supported Concurrent Users | 10+ (depending on hardware)               |
| Audio Processing           | Real-time for files up to 50MB            |



### ğŸ¤ Contributing

Fork the repository
Create a feature branch (git checkout -b feature/amazing-feature)
Commit your changes (git commit -m 'Add amazing feature')
Push to the branch (git push origin feature/amazing-feature)
Open a Pull Request


### ğŸ“ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

### ğŸ™ Acknowledgments

- **Original Research:** Jeffrey Luo, Monta Vista High School  
- **Audio Processing:** Built with Librosa  
- **UI Components:** Powered by Shadcn/ui  
- **Model Architecture:** Inspired by VGG networks  

---

### ğŸ“¦ Release Notes v1.0.0

âœ… Initial release with full-stack implementation  
âœ… 8-dimension emotion analysis  
âœ… Modern React UI with theme support  
âœ… Real-time processing and results display  

Made with â¤ï¸ for music emotion analysis


